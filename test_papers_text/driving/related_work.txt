2 RELATED WORK This paper is related to the research topics UX, XAI, user trust and acceptance. It is applied in the context of frst-time users or users with little experience in autonomous driving. This paper is based on the following theoretical background and related to the following similar applications.

2.1 User Experience Design When users encounter digital products, their interactions are complex, dynamic and subjective. UXD provides methods to create meaning and emotions during these product interactions [15, 23]. Designing for UX supports designers in creating product interactions and potentially associated emotions, even though emotions cannot be designed for directly due to their subjectiveness [8, 23]. This subjectiveness of UX can trigger feelings that cause users to continue or stop their current product interaction [32]. For the experimental setup below, the following models are used to evaluate the system interaction.

2.1.1 The Model of Pragmatic and Hedonic Qalities. The model of pragmatic and hedonic qualities is a reductionist model of UX to measure the subjectiveness of UX by using a questionnaire [21]. It consolidates single experiences at diferent abstraction levels, so-called meta experiences, to analyse the pragmatic and hedonic dimension. The pragmatic dimension focuses on usability and ease of use to achieve intended goals during the interaction. The hedonic dimension focuses on the satisfaction of the users’ well-being during the interaction based on the theory of universal psychological needs [21, 22]. The User Experience Questionnaire - Short (UEQ-S) [46] is a semantic diferential questionnaire based on the model of pragmatic and hedonic qualities that provides a measurement for UX. It applies a seven-point Likert scale for eight items, four of which to measure the pragmatic and hedonic quality each.

2.1.2 The Autonomous Vehicle Acceptance Model. Hewitt et al. [25] have proposed a model to assess the acceptance of AVs, the Autonomous Vehicle Acceptance Model Questionnaire (AVAM). The model aims at addressing user engagement and control when interacting with the AV, rather than technological aspects of vehicles and their degree of autonomy. The AVAM consists of 26 items and 3 interaction control aspects, measured on a seven-point Likert scale. Out of the 26 items, the following factors are measured: Performance Expectancy, Efort Expectancy, Social Infuence, Facilitating Conditions, Attitude Towards (Using) Technology, Self-Efcacy, Anxiety, Behavioural Intention (to use the vehicle), and Perceived Safety.

2.2 Explainable AI Explainable AI (XAI) [1, 10, 40] is concerned with methods to explain why an AI algorithm predicts a certain result. Explanations can be used for knowledge discovery, model verifcation, model improvement, but also user acceptance. For AI developers, XAI helps to evaluate and improve AI models. For end-users, it helps to clarify and improve the interaction with an AI system. With regard to machine learning methods, XAI techniques have been developed rather to analyse technical aspects than to present the explanations to end-users [11]. As Samek and Müller point out “the optimisation of explanations for optimal human usage is still a challenge which needs further study” [45, p. 17].

Technical explanation possibilities of an AI system may not necessarily be adequate or applicable for what end-users need in a specific situation [50]. Individual users have particular needs and preferences with regard to explanations under diferent conditions, which a system should take into account [39]. The combination of XAI and human reasoning is expected to beneft the humanAI-interaction [42] and individual needs during human reasoning can be addressed by diferent XAI methods [48]. XAI is one aspect to support transparency in the human-AI interaction [27]. Furthermore, transparency is also strongly recommended by diferent guidelines for AI system design [26, 30]. The European Commission’s guidelines [26], for instance, emphasise that explanations from an AI systems should address the stakeholder concerns.

Connecting UXD and XAI to increase transparency in the humanAI interaction motivates this paper. Although no specifc XAI methods or implementations are used directly, diferent explanation information types are evaluated for their efect on end-user interactions and UX. The results contribute to a better understanding when and how explanations can support the user interaction and potentially increase the UX.

2.3 Autonomous Vehicle Interaction As of yet, the technical requirements to reach the level of autonomous or automated driving is an ongoing research topic [36]. Several aspects have to be taken into account for the interaction between human users and semi-automated vehicles [16]. Design recommendations are already available for semi-automated driving, e.g., handover scenarios [41]. For trust and user acceptance, transparency in the decision-making of the autonomous shuttles is essential [29].

Communicating AI decisions play an important role in autonomous driving. The study of Jeon et al. has shown that passengers want to be in control of the AV at any time [31]. This is particularly important in urban areas with a high number of simultaneous trafc situations, as this can lead to trust issues and the fear of automation failures [17]. An AV should thus communicate its awareness and intent to increase the feeling of control and security for passengers. UX and the feeling of trust in the system also increase when presenting additional information to passengers, such as head-up visualisations [24]. Trust is also increased in particularly difcult driving scenarios [49].

Besides internal communication between vehicles and passengers, external communication is also relevant for the communication with other trafc participants [9] and can have a positive efect on UX and pedestrians’ attitude towards AVs [13].

Explaining the behaviour of autonomous systems can increase the user’s understanding of their actions, and the overall transparency [27, 51]. Explanations of AVs before their acting can further improve the user trust [20].

When designing awareness and intent, designers should focus on providing so-called why-information [34]. One way of designing such a system can be feedback communicated through light [14, 37]. Another way to communicate awareness and intent is a visualisation with object recognition [12]. User trust in AVs has also been shown for driving performance and measured comfort [47], at least in the context of semi-autonomous vehicles. Furthermore, for visual communication text, icons, and augmented reality should be used together [18]. While trust in autonomous vehicles also increases over time [44] and passengers will most likely use their driving time for other activities than following the trafc and vehicle behaviour [33], we explicitly focus on frst-time users or users with little experiences to facilitate their acceptance and UX.