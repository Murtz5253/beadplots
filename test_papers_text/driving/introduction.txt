1 INTRODUCTION In the case of autonomous driving, replacing the human driver with an artifcial intelligence (AI) may lead to users that are sceptical towards the system. Subjective well-being is decreased and therefore, user experience (UX) is less positive. As Hartwich et al. demonstrated, passengers prefer human drivers over autonomous vehicles, even though the ride was identical [19]. The negative experiences may be, for example, due to users not being in control of the system, not being able to actively engage in the situation, disapproving the driving style, or not yet being familiar with autonomous vehicles (AVs) and their services [28, 38]. However, easy accessibility and practicability also show that users have an interest and curiosity in such new technology [44].

An in-depth survey is provided by Miller [39] on requirements for system explanations for humans. So far, only a few approaches have investigated whether available methods for explanations from AI systems can be directly provided to end-users [4, 5, 35]. Yet, the question is how to implement insights from human needs for explanation and how to comply with regulations for transparency for a specifc use case that also benefts the system design with regard to UX. This is also of interest, as design guidelines for AI systems are available that recommend or even require systems to be transparent and explain themselves to developers, and end-users [26].

This paper focusses on vehicles with full driving automation (SAE level 5 [43]) and investigates if system explanations can improve the UX during autonomous rides. We conducted a user study to determine whether explanations of the system during or after an autonomous ride can improve the experience with the AV, or even support passengersâ€™ well-being. The focus was on frst-time users or users who had only a few experiences with AVs so far. The study intersects with the following two felds of research: (1) User Experience Design (UXD) and interaction design which aim at providing a positive human-computer interaction and (2) Explainable Artifcial Intelligence (XAI) that aims at increasing transparency in system behaviour and insights in system predictions.